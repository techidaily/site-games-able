---
title: "A Tale of Three Missteps: My RTX 4090 Journey"
date: 2024-07-03T12:01:21.139Z
updated: 2024-07-04T12:01:21.139Z
tags:
  - games
categories:
  - games
description: "This Article Describes A Tale of Three Missteps: My RTX 4090 Journey"
excerpt: "This Article Describes A Tale of Three Missteps: My RTX 4090 Journey"
keywords: RTX 4090 Experience,Graphics Card Saga,Tech Gaming Tale,High-End GPU Journey,Missteps in Tech Upgrade,PC Performance Story,Next-Gen Graphics Test
thumbnail: https://thmb.techidaily.com/b7b45cfdc35344213e5101907c39a4f8622c548d37868126691840befd4a8d38.jpg
---

## A Tale of Three Missteps: My RTX 4090 Journey

### Quick Links

* [My GPU Usage Is Far From 100 Percent](#my-gpu-usage-is-far-from-100-percent)
* [Power Consumption Is Very High](#power-consumption-is-very-high)
* [Too Expensive for Diminishing Returns](#too-expensive-for-diminishing-returns)

### Key Takeaways

* The games I normally play don't utilize my RTX 4090 fully, and my CPU holds its performance back at 1440p resolution.
* At full power, the RTX 4090 can easily draw over 450W, which isn't ideal if you want to keep your electricity bills in check.
* Consider the RTX 4080 Super if you don't plan to play games at 4K resolution. It's far less power hungry with a 320W TDP.

 Despite launching in 2022, the RTX 4090 is still the world's fastest graphics card as of early 2024\. Although I enjoyed using it to play AAA games over the past year and a half, I still regret buying it for a few reasons.

## 1 My GPU Usage Is Far From 100 Percent

 My biggest issue since upgrading to the RTX 4090 is that my graphics card is often not fully utilized. And that's due to a couple of factors.

 Firstly, the games that I usually play are more CPU-intensive rather than GPU-intensive. Valorant, Call of Duty: Warzone, and Fortnite are some of the games that I play regularly.

 Secondly, I rarely play games at 4K resolution. Note that at lower resolutions, games put more stress on the CPU rather than the GPU to push more frames. To get more GPU usage in these situations, you need the fastest CPU you can possibly get.

 I have a triple-monitor setup where the primary monitor is a 1440p 360Hz panel. I only use my 4K 160Hz monitor to play single-player AAA titles like Assassin's Creed Mirage and Avatar: Frontiers of Pandora.

 Therefore, in games like Valorant, my GPU usage is not even close to 100 percent. Take a look at the screenshot below, where my RTX 4090 is pushing nearly 500FPS at 35% GPU usage.

![RTSS OSD stats appearing in Valorant](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2024/04/rtss-osd-stats-appearing-in-valorant.png)

 Even in graphically demanding AAA games, my GPU usage rarely exceeds 90 percent. And that's because my CPU can't keep up. I use a Ryzen 5900X, which is a generation older than the top-of-the-line AMD Ryzen processors available today, like [the Ryzen 7800X3D, 7900X3D, and 7950X3D](https://www.makeuseof.com/ryzen-9-7950x3d-vs-ryzen-9-7900x3d-vs-ryzen-7-7800x3d/) .

## 2 Power Consumption Is Very High

 The RTX 4090 is a monster of a GPU that consumes a lot of power. The Founders Edition (reference) version of the RTX 4090 has a [TDP (Thermal Design Power)](https://www.makeuseof.com/tag/thermal-design-power-technology-explained/) of 450W. This means the GPU can consume up to 450W under general usage.

 However, the RTX 4090 I own is no ordinary unit. It's the Colorful iGame RTX 4090 Neptune, a liquid-cooled variant with a 360mm radiator that has a TDP of 630W! Like this one, several RTX 4090 variants from NVIDIA's board partners have a TDP higher than 450W.

 When I play Cyberpunk 2077 at 4K resolution with maxed-out settings, the GPU easily consumes 500W, which is way too much for someone who just plays games. In comparison, the RTX 4080 Super, NVIDIA's second-best offering, has a 320W TDP, which is a lot more manageable for someone looking to keep their electricity bills in check.

![a triple-monitor PC gaming setup with Cyberpunk 2077 running on the main display](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/wm/2024/04/a-triple-monitor-pc-gaming-setup-with-cyberpunk-2077-running-on-the-main-display.jpg)

 Hamlin Rozario/[MakeUseOf](https://www.makeuseof.com/author/hamlin-rozario/)

 That said, it's worth noting that power draw isn't a major issue when I'm playing less GPU-demanding games like Valorant or Fortnite because the GPU usage is typically low.

## 3 Too Expensive for Diminishing Returns

 Lastly, it comes down to the money I spent on this graphics card. NVIDIA launched the RTX 4090 with an MSRP of $1,599, which is already way too expensive for a graphics card.

 However, the Colorful Neptune RTX 4090 I have cost me a little over two grand, but at that time, I thought it was worth it because of the overclocking headroom I got from liquid cooling. Another reason is that this card isn't nearly as chunky as other air-cooled RTX 4090 cards on the market.

 Unfortunately, I haven't even come close to maximizing the RTX 4090's full potential because of the kind of games I mostly play. I now feel like I could've spent half the money on an RTX 4080 for similar frame rates on esports titles like Valorant, Overwatch 2, or Fortnite. To get the most out of my RTX 4090 now, I need one of [the fastest gaming CPUs from AMD or Intel](https://www.makeuseof.com/amd-vs-intel-gaming/) .

 So, if you're on the fence about buying an RTX 4090, think about the games you play and the resolution you play at because I don't want you to make the same mistake as I did. I wouldn't recommend buying an RTX 4090 if you don't plan to play AAA games at 4K resolution regularly.


<ins class="adsbygoogle"
     style="display:block"
     data-ad-format="autorelaxed"
     data-ad-client="ca-pub-7571918770474297"
     data-ad-slot="1223367746"></ins>



<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-7571918770474297"
     data-ad-slot="8358498916"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>


